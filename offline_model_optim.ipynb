{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from flask import Flask, request, jsonify\n",
    "from botocore.errorfactory import ClientError\n",
    "import structlog  # for event logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the environment files\n",
    "load_dotenv()\n",
    "s3_resource = boto3.resource('s3',\n",
    "                             endpoint_url=os.getenv('ENDPOINT_URL'),\n",
    "                             aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "                             aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "                             aws_session_token=None,\n",
    "                             config=boto3.session.Config(signature_version='s3v4'),\n",
    "                             verify=False\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_s3_bucket(file_name: str, bucket_name=\"joined-out\"):\n",
    "    # read all the files in the bucket\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "    found = False\n",
    "    data = \"\"\n",
    "    for obj in bucket.objects.all():\n",
    "        key = obj.key\n",
    "        if file_name in str(key):\n",
    "            body = obj.get()['Body'].read()\n",
    "            \n",
    "            if isinstance(body, bytes):\n",
    "                body = body.decode()\n",
    "            elif not isinstance(body, str):\n",
    "                body = str(body)\n",
    "                \n",
    "            print(\"%s : length = %s\" % (key, len(body)))\n",
    "                \n",
    "            data += body\n",
    "            # data = body\n",
    "            # data.append(body)\n",
    "            found = True\n",
    "    if found:\n",
    "        return data\n",
    "    else:\n",
    "        print(\"ERROR KEY NOT FOUND\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/_SUCCESS : length = 0\n",
      "out/part-00000-28743dcb-7f7e-4000-ab03-e38baf795fe1-c000.json : length = 44613071\n",
      "out/part-00001-28743dcb-7f7e-4000-ab03-e38baf795fe1-c000.json : length = 44990855\n",
      "out/part-00002-28743dcb-7f7e-4000-ab03-e38baf795fe1-c000.json : length = 44710523\n",
      "out/part-00003-28743dcb-7f7e-4000-ab03-e38baf795fe1-c000.json : length = 45277188\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DEBUG = True\n",
    "# read in all the data from S3 as one big string\n",
    "data = read_from_s3_bucket(file_name=\"out/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "Type: <class 'list'> of type: <class 'dict'>, Len 100000\n"
     ]
    }
   ],
   "source": [
    "# Split the string of data into individual lines. Only works because backslash is escaped in string.\n",
    "data = data.split('\\n')\n",
    "data = data[0:-1]\n",
    "if DEBUG: print(len(data))\n",
    "\n",
    "# convert every entry in the list to a JSON object. \n",
    "records = []\n",
    "for i in range(len(data)):\n",
    "    record = json.loads(data[i])\n",
    "    record['email_object'] = json.loads(record['email_object'])\n",
    "    record['to'] = record['email_object']['to']\n",
    "    record['body'] = record['email_object']['body']\n",
    "    record['from'] = record['email_object']['from']\n",
    "    record['subject'] = record['email_object']['subject']\n",
    "    records.append(record)\n",
    "\n",
    "if DEBUG: print(\"Type: %s of type: %s, Len %d\" % (type(records), type(records[0]), len(records)))\n",
    "# if DEBUG: print(json.dumps(records[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 39590 to 53604\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count   Dtype              \n",
      "---  ------              --------------   -----              \n",
      " 0   email_id            100000 non-null  int64              \n",
      " 1   received_timestamp  100000 non-null  datetime64[ns, UTC]\n",
      " 2   email_object        100000 non-null  object             \n",
      " 3   event               64504 non-null   category           \n",
      " 4   label               100000 non-null  category           \n",
      " 5   timestamp           64504 non-null   datetime64[ns, UTC]\n",
      " 6   to                  100000 non-null  object             \n",
      " 7   body                100000 non-null  object             \n",
      " 8   from                100000 non-null  object             \n",
      " 9   subject             100000 non-null  object             \n",
      "dtypes: category(2), datetime64[ns, UTC](2), int64(1), object(5)\n",
      "memory usage: 7.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load the data into a dataframe and set proper types\n",
    "df = pd.DataFrame(records)\n",
    "df['received_timestamp'] = pd.to_datetime(df['received_timestamp'], utc=True)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "df['label'] = df['label'].astype('category')\n",
    "df['event'] = df['event'].astype('category')\n",
    "df = df.sort_values(by='received_timestamp')\n",
    "df[['to', 'from', 'body', 'subject']] = df[['to', 'from', 'body', 'subject']].fillna(value=\"\")\n",
    "\n",
    "if DEBUG: print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>received_timestamp</th>\n",
       "      <th>email_object</th>\n",
       "      <th>event</th>\n",
       "      <th>label</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>to</th>\n",
       "      <th>body</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39590</th>\n",
       "      <td>45701</td>\n",
       "      <td>2023-01-11 20:26:26.701000+00:00</td>\n",
       "      <td>{'to': 'the00@speedy.uwaterloo.ca', 'body': '\n",
       "...</td>\n",
       "      <td>email::id::label::put</td>\n",
       "      <td>spam</td>\n",
       "      <td>2023-01-11 20:26:26.741625+00:00</td>\n",
       "      <td>the00@speedy.uwaterloo.ca</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nDo you feel the pressure to perf...</td>\n",
       "      <td>\"Tomas Jacobs\" &lt;RickyAmes@aol.com&gt;</td>\n",
       "      <td>Generic Cialis, branded quality@</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       email_id               received_timestamp  \\\n",
       "39590     45701 2023-01-11 20:26:26.701000+00:00   \n",
       "\n",
       "                                            email_object  \\\n",
       "39590  {'to': 'the00@speedy.uwaterloo.ca', 'body': '\n",
       "...   \n",
       "\n",
       "                       event label                        timestamp  \\\n",
       "39590  email::id::label::put  spam 2023-01-11 20:26:26.741625+00:00   \n",
       "\n",
       "                              to  \\\n",
       "39590  the00@speedy.uwaterloo.ca   \n",
       "\n",
       "                                                    body  \\\n",
       "39590  \\n\\n\\n\\n\\n\\n\\nDo you feel the pressure to perf...   \n",
       "\n",
       "                                     from                            subject  \n",
       "39590  \"Tomas Jacobs\" <RickyAmes@aol.com>  Generic Cialis, branded quality@   "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 70000\tValidation Size: 10000\tTest Size: 20000\n"
     ]
    }
   ],
   "source": [
    "# Perform Time Based Split\n",
    "n = len(df)\n",
    "train_amt = int(0.7 * n)\n",
    "test_amt = int(0.2 * n)\n",
    "validation_amt = int(0.1 * n)\n",
    "# split the dataframe by slicing based on index. Only works due to being sorted by time.\n",
    "# training_targets = ['to', 'from', 'body', 'subject']\n",
    "training_targets =['body']\n",
    "train_x = df.iloc[0:train_amt][training_targets]\n",
    "train_y = df.iloc[0:train_amt]['label']\n",
    "validation_x = df.iloc[train_amt:validation_amt + train_amt][training_targets]\n",
    "validation_y = df.iloc[train_amt:validation_amt + train_amt]['label']\n",
    "test_x = df.iloc[train_amt + validation_amt:n][training_targets]\n",
    "test_y = df.iloc[train_amt + validation_amt:n]['label']\n",
    "if DEBUG: print(\"Train Size: %d\\tValidation Size: %d\\tTest Size: %d\" % (len(train_x), len(validation_x), len(test_x)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({'spam': 45133, 'ham': 24867})\n",
      "Resampled dataset shape Counter({'ham': 24867, 'spam': 24867})\n",
      "(49734,)\n",
      "(49734, 1)\n"
     ]
    }
   ],
   "source": [
    "# Deal with Class Imbalance by undersampling the majority for training\n",
    "y_orig = train_y\n",
    "x_orig = train_x # truncated?\n",
    "if DEBUG: print('Original dataset shape {}'.format(Counter(y_orig)))\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "x, y = rus.fit_resample(x_orig, y_orig)\n",
    "if DEBUG: print('Resampled dataset shape {}'.format(Counter(y)))\n",
    "train_x = x\n",
    "train_y = y\n",
    "if DEBUG: print(train_y.shape)\n",
    "if DEBUG: print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPerforming Text Classification\\n\\nGridSearch Params:\\nCountVectorizer parameters,\\nModel types,\\nModel Hyperparameters\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Performing Text Classification\n",
    "\n",
    "GridSearch Params:\n",
    "CountVectorizer parameters,\n",
    "Model types,\n",
    "Model Hyperparameters\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/65242617/sklearn-pipeline-with-countvectorizer-and-category-on-a-pandas-dataframe\n",
    "# https://towardsdatascience.com/natural-language-processing-on-multiple-columns-in-python-554043e05308\n",
    "# https://stackoverflow.com/a/55401454 for grid search info\n",
    "\n",
    "# Apparently can only countvectorizer on one column... May need to handle the others as categories\n",
    "\n",
    "text_preprocessing1 = Pipeline([\n",
    "    ('Vect', CountVectorizer()),\n",
    "    ('Tsvd', TruncatedSVD(n_components=10))\n",
    "    ])\n",
    "text_preprocessing2 = Pipeline([\n",
    "    ('Vect', CountVectorizer())\n",
    "    ])\n",
    "text_preprocessing3 = Pipeline([\n",
    "    ('Vect', CountVectorizer(stop_words='english', min_df=10)),\n",
    "    ('Tsvd', TruncatedSVD(n_components=10))\n",
    "    ])\n",
    "text_preprocessing4 = Pipeline([\n",
    "    ('Vect', CountVectorizer(stop_words='english', min_df=10))\n",
    "    ])\n",
    "text_preprocessing5 = Pipeline([('BOW', TfidfVectorizer(ngram_range=(1, 3), max_features=1000))])\n",
    "\n",
    "classifier1 = Pipeline([\n",
    "    ('svc', svm.SVC())\n",
    "    ])\n",
    "\n",
    "classifier2 = Pipeline([\n",
    "    ('ridge', RidgeClassifier())\n",
    "    ])\n",
    "\n",
    "classifier3 = Pipeline([\n",
    "    ('rf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "preprocessors = [text_preprocessing1, text_preprocessing2, text_preprocessing3, text_preprocessing4, text_preprocessing5]\n",
    "classifiers = [classifier1, classifier2, classifier3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49734, 1)\n",
      "(49734,)\n",
      "(20000, 1)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_x\n",
    "y_train = train_y.squeeze()\n",
    "x_test = test_x\n",
    "y_test = test_y\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer()),\n",
      "                                                                  ('Tsvd',\n",
      "                                                                   TruncatedSVD(n_components=10))]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('svc', SVC())]))])\n",
      "ROC_AUC: 0.91\n",
      "F1: 0.90\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer()),\n",
      "                                                                  ('Tsvd',\n",
      "                                                                   TruncatedSVD(n_components=10))]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('ridge', RidgeClassifier())]))])\n",
      "ROC_AUC: 0.83\n",
      "F1: 0.83\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer()),\n",
      "                                                                  ('Tsvd',\n",
      "                                                                   TruncatedSVD(n_components=10))]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('rf', RandomForestClassifier())]))])\n",
      "No Decision function. Using predict_proba\n",
      "ROC_AUC: 1.00\n",
      "F1: 0.97\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer())]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('svc', SVC())]))])\n",
      "ROC_AUC: 0.98\n",
      "F1: 0.97\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer())]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('ridge', RidgeClassifier())]))])\n",
      "ROC_AUC: 1.00\n",
      "F1: 0.98\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer())]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('rf', RandomForestClassifier())]))])\n",
      "No Decision function. Using predict_proba\n",
      "ROC_AUC: 1.00\n",
      "F1: 0.98\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer(min_df=10,\n",
      "                                                                                   stop_words='english')),\n",
      "                                                                  ('Tsvd',\n",
      "                                                                   TruncatedSVD(n_components=10))]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('svc', SVC())]))])\n",
      "ROC_AUC: 0.89\n",
      "F1: 0.91\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer(min_df=10,\n",
      "                                                                                   stop_words='english')),\n",
      "                                                                  ('Tsvd',\n",
      "                                                                   TruncatedSVD(n_components=10))]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('ridge', RidgeClassifier())]))])\n",
      "ROC_AUC: 0.83\n",
      "F1: 0.84\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer(min_df=10,\n",
      "                                                                                   stop_words='english')),\n",
      "                                                                  ('Tsvd',\n",
      "                                                                   TruncatedSVD(n_components=10))]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('rf', RandomForestClassifier())]))])\n",
      "No Decision function. Using predict_proba\n",
      "ROC_AUC: 1.00\n",
      "F1: 0.97\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer(min_df=10,\n",
      "                                                                                   stop_words='english'))]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('svc', SVC())]))])\n",
      "ROC_AUC: 0.99\n",
      "F1: 0.97\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer(min_df=10,\n",
      "                                                                                   stop_words='english'))]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('ridge', RidgeClassifier())]))])\n",
      "ROC_AUC: 0.99\n",
      "F1: 0.97\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer(min_df=10,\n",
      "                                                                                   stop_words='english'))]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('rf', RandomForestClassifier())]))])\n",
      "No Decision function. Using predict_proba\n",
      "ROC_AUC: 1.00\n",
      "F1: 0.98\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('BOW',\n",
      "                                                                   TfidfVectorizer(max_features=1000,\n",
      "                                                                                   ngram_range=(1,\n",
      "                                                                                                3)))]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('svc', SVC())]))])\n",
      "ROC_AUC: 0.98\n",
      "F1: 0.98\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('BOW',\n",
      "                                                                   TfidfVectorizer(max_features=1000,\n",
      "                                                                                   ngram_range=(1,\n",
      "                                                                                                3)))]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('ridge', RidgeClassifier())]))])\n",
      "ROC_AUC: 0.99\n",
      "F1: 0.97\n",
      "------------------------------------\n",
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('txt0',\n",
      "                                                  Pipeline(steps=[('BOW',\n",
      "                                                                   TfidfVectorizer(max_features=1000,\n",
      "                                                                                   ngram_range=(1,\n",
      "                                                                                                3)))]),\n",
      "                                                  'body')])),\n",
      "                ('clf', Pipeline(steps=[('rf', RandomForestClassifier())]))])\n",
      "No Decision function. Using predict_proba\n",
      "ROC_AUC: 1.00\n",
      "F1: 0.98\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if False: # Do Not re-run as the results are in a table below\n",
    "    for preprocessor in preprocessors:\n",
    "        for classifier in classifiers:\n",
    "            \n",
    "            preprocess = ColumnTransformer([\n",
    "                ('txt' + str(0), preprocessor, 'body')\n",
    "                ], remainder='passthrough')\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                            ('preprocess', preprocess),\n",
    "                            ('clf', classifier)\n",
    "                        ])\n",
    "\n",
    "            print(pipeline)\n",
    "            \n",
    "            pipe = pipeline.fit(x_train, y_train)\n",
    "            y_pred = pipe.predict(x_test)\n",
    "            try:\n",
    "                y_decision = pipe.decision_function(x_test)\n",
    "                print(\"ROC_AUC: %.2f\" % (metrics.roc_auc_score(y_test, y_decision)))\n",
    "            except Exception:\n",
    "                print(\"No Decision function. Using predict_proba\")\n",
    "                y_pred_prob = pipe.predict_proba(x_test)\n",
    "                print(\"ROC_AUC: %.2f\" % (metrics.roc_auc_score(y_test, y_pred_prob[:,1])))\n",
    "            print(\"F1: %.2f\" % (f1_score(y_test, y_pred, pos_label='spam')))\n",
    "            print(\"------------------------------------\")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelim Pipeline Search Results\n",
    "| Preprocessor | Txt Process Had Args? | CLF | ROC AUC | F1 |\n",
    "|--------------|-----------------------|-----|---------|----|\n",
    "| CV + TSVD | No | svc | 0.91 | 0.90 |\n",
    "| CV + TSVD | No | ridge | 0.83 | 0.83 |\n",
    "| CV + TSVD | No | rf | 1.00 | 0.97 |\n",
    "| CV | No | svc | 0.98 | 0.97 |\n",
    "| CV | No | ridge | 1.00 | 0.98 |\n",
    "| CV | No | rf | 1.00 | 0.98 |\n",
    "| CV + TSVD | Yes | svc | 0.89 | 0.91 |\n",
    "| CV + TSVD | Yes | ridge | 0.83 | 0.84 |\n",
    "| CV + TSVD | Yes | rf | 1.00 | 0.97 |\n",
    "| CV | Yes | svc | 0.99 | 0.97 |\n",
    "| CV | Yes | ridge | 0.99 | 0.97 |\n",
    "| CV | Yes | rf | 1.00 | 0.98 |\n",
    "| TFIDF | Yes | svc | 0.98 | 0.98 |\n",
    "| TFIDF | Yes | ridge | 0.99 | 0.97 |\n",
    "| TFIDF | Yes | rf | 1.00 | 0.98 |\n",
    "\n",
    "The above table shows the results of the model and preprocessor semi-grid search that was performed. It shows that RandomForest had an area under the ROC curve of 1 in all cases. It also had a high F1 score. The table shows that TFIDF performed similarly to the CountVectorizer on its own but was much slower. It also showed that adding the TruncatedSVD after the CountVectorizer hurt the accuracy of the model but durastically improved training time. The table showed that the Ridge classifier performed similar to the RandomForest but with slightly faster speeds. Another piece of information of note is that removing the stopwords during the CountVectorizer hurt performance.\n",
    "\n",
    "These results point towards the conclusion that we would want a CountVectorizer with Ridge classifier for the best performance. This does not take time or legibility into account though. For these reasons it is likely better to move forward using a CountVectorizer followed by a TruncatedSVD with a RandomForest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_preprocessing = Pipeline([\n",
    "    ('Vect', CountVectorizer()),\n",
    "    ('Tsvd', TruncatedSVD(n_components=10))\n",
    "    ])\n",
    "preprocess = ColumnTransformer([('pre', text_preprocessing, 'body')], remainder='passthrough')\n",
    "# classifier = Pipeline([('ridge', RidgeClassifier())])\n",
    "# classifier = Pipeline([('svc', svm.SVC())])\n",
    "# classifier = Pipeline([('rf', RandomForestClassifier())])\n",
    "# pipeline = Pipeline([\n",
    "#                         ('preprocess', preprocess),\n",
    "#                         ('clf', classifier)\n",
    "#                     ])\n",
    "pipeline = Pipeline([\n",
    "                        ('pre', preprocess),\n",
    "                        ('rf', RandomForestClassifier())\n",
    "                    ])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pre',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('pre',\n",
      "                                                  Pipeline(steps=[('Vect',\n",
      "                                                                   CountVectorizer()),\n",
      "                                                                  ('Tsvd',\n",
      "                                                                   TruncatedSVD(n_components=10))]),\n",
      "                                                  'body')])),\n",
      "                ('rf', RandomForestClassifier())])\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.1' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# parameters = {\n",
    "#   'rf__n_estimators':[1,10,100,1000],\n",
    "#   'rf__min_samples_split': [2,3,4,5],\n",
    "#   'rf__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "#   'rf__max_depth': [None, 10, 100],\n",
    "#   'rf__max_features': [None, 'sqrt', 'log2'],\n",
    "#   'rf__n_jobs': [-1],\n",
    "#   'rf__random_state': [42]\n",
    "#   }\n",
    "parameters = {\n",
    "  'rf__n_estimators':[1,10,100,1000],\n",
    "  'rf__min_samples_split': [2,4],\n",
    "  'rf__n_jobs': [-1],\n",
    "  'rf__random_state': [42]\n",
    "  }\n",
    "# initialize\n",
    "grid_pipeline = GridSearchCV(pipeline, parameters, cv=1, verbose=2, n_jobs=-1, scoring='roc_auc')\n",
    "# fit\n",
    "grid_pipeline.fit(x_train, y_train)\n",
    "grid_pipeline.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pipe = pipeline.fit(x_train, y_train)\n",
    "# print(pipeline.score(x_train, y_train))\n",
    "\n",
    "pipe = grid_pipeline\n",
    "\n",
    "y_pred = pipe.predict(x_test)\n",
    "try:\n",
    "    y_decision = pipe.decision_function(x_test)\n",
    "    print(\"ROC_AUC: %.2f\" % (metrics.roc_auc_score(y_test, y_decision)))\n",
    "except Exception:\n",
    "    print(\"No Decision function. Using predict_proba\")\n",
    "    y_pred_prob = pipe.predict_proba(x_test)\n",
    "    print(\"ROC_AUC: %.2f\" % (metrics.roc_auc_score(y_test, y_pred_prob[:,1])))\n",
    "print(\"F1: %.2f\" % (f1_score(y_test, y_pred, pos_label='spam')))\n",
    "print(\"Accuracy: %.2f\" % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision: %.2f\" % (metrics.precision_score(y_test, y_pred, average='weighted', zero_division=0)))\n",
    "print(\"Recall: %.2f\" % (metrics.recall_score(y_test, y_pred, average='weighted')))\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# pipe = pipeline.fit(x_train, y_train)\n",
    "# # y_pred = pipe.predict(x_test)\n",
    "# y_decision = pipe.decision_function(x_test)\n",
    "# print(\"ROC_AUC: %.2f\" % (metrics.roc_auc_score(y_test, y_decision)))\n",
    "# svc_disp = metrics.RocCurveDisplay.from_estimator(pipe, x_test, y_test)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare the data by running the count vectorizer and tsvd. \n",
    "# # Want Tfidf eventually. Also want to use other data than just body\n",
    "# vectorizer = CountVectorizer(binary=True)\n",
    "# vect = TruncatedSVD()\n",
    "# x_train = vect.fit_transform(vectorizer.fit_transform(x['body']))\n",
    "# y_train = y\n",
    "# x_valid = vect.fit_transform(vectorizer.fit_transform(validation_x['body']))\n",
    "# y_valid = validation_y\n",
    "# x_test = vect.fit_transform(vectorizer.fit_transform(test_x['body']))\n",
    "# y_test = test_y\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = svm.SVC(kernel='linear')\n",
    "# clf.fit(x_train, y_train)\n",
    "# y_pred = clf.predict(x_test)\n",
    "# # y_pred_prob = clf.predict_proba(x_test)\n",
    "# y_decision = clf.decision_function(x_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(\"Accuracy: %.2f\" % (metrics.accuracy_score(y_test, y_pred)))\n",
    "# # print(\"Precision: %.2f\" % (metrics.precision_score(y_test, y_pred, average='weighted', zero_division=0)))\n",
    "# # print(\"Recall: %.2f\" % (metrics.recall_score(y_test, y_pred, average='weighted')))\n",
    "# print(\"ROC_AUC: %.2f\" % (metrics.roc_auc_score(y_test, y_decision)))\n",
    "# svc_disp = metrics.RocCurveDisplay.from_estimator(clf, x_test, y_test)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
